---
title: "Decision Trees Lab"
author: "Joe Sato"
date: "6/17/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Setups

```{r}
set.seed(1)
#Contains the dataset Boston
library(MASS)

#Package for Random Forest
library(randomForest)

#Train Dataset (?)
train = sample (1: nrow(Boston), nrow(Boston)/2)

#Test Dataset (?)
medv=Boston [-train ,"medv"]
```

## Examine Boston Data: plot medv/each predictor (non-categorical ones)

```{r}
#Per capita crime rate by town
plot(log(Boston$crim), Boston$medv) #not sure if log transform on the predictor is ok

#Avg. # of rooms per dwelling
plot(Boston$rm, Boston$medv) #decent linear relationship

#Proportion of owner-occupied units built prior to 1940
plot(Boston$age, Boston$medv) #negative linear relationship, makes sense

#Weighted mean of distances to 5 Boston employment centres
plot(Boston$dis, Boston$medv) #why is it kinda positive linear; should be negative

#Lower status of the population (percent)
plot(Boston$lstat, Boston$medv) #"lower status"? The reputation of town?
```

## Perform Bagging
```{r}
set.seed(1)

#Perform Bagging
bag.boston1 = randomForest(medv~., data=Boston, subset=train,
mtry=13, importance =TRUE)

bag.boston1

#Make a prediction
yhat.bag1 = predict (bag.boston1, newdata=Boston[-train,])

#Measured squared error
MSEbag <- mean((yhat.bag1 - medv)^2)
```

## Bagging with # of trees specified (n=25)

```{r}
bag.boston2 = randomForest(medv~., data=Boston, subset=train,
mtry=13, ntree=25)

yhat.bag2 = predict (bag.boston2, newdata=Boston[-train,])

#Measured squared error: larger than the previously calculated MSE
MSEbag25 <- mean((yhat.bag2 - medv)^2)
```

## Grow a Random Forest

```{r}
set.seed (1)

rf.boston = randomForest(medv~., data=Boston, subset=train,
mtry=6, importance =TRUE)

yhat.rf = predict (rf.boston, newdata=Boston[-train,])

#MSE
MSErf <- mean( (yhat.rf - medv)^2 )
```

## Fit Linear Regression 

### Identify a justifiable linear model via variable elimination
Seek to eliminate the predictors of little importance via p-values; linear regression is not the objective here, so no need to do this intricately. Below is shown that crim, indus, chas,age, and tax have relatively high p-values, so eliminate these. (Though eliminating age is a little concerning.)

```{r}
#Fit linear regression 
f0 <- lm(data=Boston, medv ~ .)
summary(f0)$coefficients[,4]#each p-value
```

The list below shows that zn and rad have relatively large p-values; eliminate these two. 

```{r}
#Fit linear regression without the five predictors 
f1 <- lm(data=Boston, medv ~ . - crim - indus - chas - age - tax)
summary(f1)$coefficients[,4]#each p-value
```

The result below shows that all remaining predictors have infinitisimal p-values (except "black"), justifying the precedent steps.  
```{r}
f2 <- lm(data=Boston, medv ~ . - crim - indus - chas - age - tax - zn - rad )
summary(f2)$coefficients[,4]
```

### Make predictions on medv using f0 & f2

```{r}
#Prediction of medv by f2 using "train"
f2pred <- predict(f2, newdata=Boston[-train,])

MSEf2 <- mean ((f2pred-medv)^2)

#Prediction of medv by f0 using "train"
f0pred <- predict(f0, newdata=Boston[-train,])

MSEf0 <- mean ((f0pred-medv)^2)#smaller than MSEf2; probably related to R^2 always increasing
```

## Compare MSE-s

Below is the list of the mean squared errors for Bagging, Bagging with ntrees=25, Random Forest, Linear Regression with all 13 predictors(f0), and Linear Regression with selected predictors(f2); Random Forest resulted in the smallest MSE.
```{r}
MSEs <- matrix(c(MSEbag,MSEbag25,MSErf,MSEf0,MSEf2), nrow=1, ncol=5,byrow=TRUE)
colnames(MSEs) <- c("Bagging","Bagging: n=25", "Random Forest", "LR: f0", "LR:f2")
MSEs
```

## Compute Prediction Intervals for f0 & f2

```{r}
#Predction intervals by f0 for each observed value of medv
PIf0 <- predict(f0, newdata=Boston[-train,], interval="prediction", level=0.95)#too much gap between up & low? 

#Count how many of yhat.rf values lie in the prediction intervals by PIf0
YN <- c(rep(NA,253))
for (k in 1:253) {
  if (yhat.rf[k] <= PIf0[k,3] & yhat.rf[k] >= PIf0[k,2]) {YN[k] <- "Y"}
  else {YN[k] <- "N"}
}

t=0
#Count the number of Y in YN, then compute #Y/253
for (k in 1:253) {
  if (YN[k] == "Y"){t <- t+1}
}
t
```

Thus, among the 253 predictions made by Random Forest, 251 of them lie in the corresponding prediction intervals obtained by Linear Regression model with all 13 predictors(f0).

```{r}
#Predction intervals by f2 for each observed value of medv
PIf2 <- predict(f2, newdata=Boston[-train,], interval="prediction", level=0.95)

#Count how many of yhat.rf values lie in the prediction intervals by PIf2
YN2 <- c(rep(NA,253))
for (k in 1:253) {
  if (yhat.rf[k] <= PIf2[k,3] & yhat.rf[k] >= PIf2[k,2]) {YN2[k] <- "Y"}
  else {YN2[k] <- "N"}
}

t2=0
#Count the number of Y in YN2, then compute #Y/253
for (k in 1:253) {
  if (YN2[k] == "Y"){t2 <- t2+1}
}
t2
```

Thus, among the 253 predictions made by Random Forest, 252 of them lie in the corresponding prediction intervals obtained by Linear Regression model with selected predictors(f2). 


```{r}
#Count how many of medv values lie in the prediction intervals by PIf2
YN3 <- c(rep(NA,253))
for (k in 1:253) {
  if (medv[k] <= PIf2[k,3] & medv[k] >= PIf2[k,2]) {YN3[k] <- "Y"}
  else {YN3[k] <- "N"}
}

#Count the number of Y in YN2, then compute #Y/253
t3=0

for (k in 1:253) {
  if (YN3[k] == "Y"){t3 <- t3+1}
}

t3
```

Thus, 240/253 = 94.9% of the medv values (the test data) lie in the prediction intervals obtained via f2

```{r}
#Count how many of medv values lie in the prediction intervals by PIf0
YN4 <- c(rep(NA,253))
for (k in 1:253) {
  if (medv[k] <= PIf0[k,3] & medv[k] >= PIf0[k,2]) {YN4[k] <- "Y"}
  else {YN4[k] <- "N"}
}

#Count the number of Y in YN2, then compute #Y/253
t4=0

for (k in 1:253) {
  if (YN4[k] == "Y"){t4 <- t4+1}
}

t4
```

Thus, 242/253 = 95.7% of the medv values (the test data) lies in the prediction intervals obtained via f0. 

## Compute Prediction Intervals for Random Forest via randomForestSRC

```{r}
library(randomForestSRC)
set.seed(1)
qrf  <- quantreg(medv~., data = Boston)

#quantile regresssion with mse splitting
qrf1 <- quantreg(medv~., data = Boston, spritrule="mse", nodesize=1)

#0.05, 0.95 quantiles 
qt <- get.quantile(qrf1, c(.05, .95)) #dim(qt)=[506 3]
```

```{r}
train2 <- Boston[train,]

#Grow Forests on the training dataset "train2"
qrf2 <-    quantreg(medv~., data = train2,  spritrule="mse", nodesize=1)

#Apply the grown model on the test set Boston[-train,]
qrTest2 <- quantreg(object=qrf2, newdata=Boston[-train,])

#Get the prediction intervals for the predictions on the test set
qt2 <- get.quantile(qrTest2, c(.05,.95))

#qrTest2$predicted

#qrf22 <- quantreg(medv~., data=train2)
#qtTest <- quantreg(object=qrf22, newdata=Boston[-train2,])
#qtPItest <- get.quantile(qtTest, c(.05, .95))
```

```{r}
#Count how many of medv values lie in the prediction intervals by qtPItest
YN4 <- c(rep(NA,253))
for (k in 1:253) {
  if (qt2[k,1] <= medv[k]  & medv[k] <= qt2[k,2]) {YN4[k] <- "Y"}
  else {YN4[k] <- "N"}
}

t4=0
#Count the number of Y in YN4, then compute #Y/253
for (k in 1:253) {
  if (YN4[k] == "Y"){t4 <- t4+1}
}
t4
```

Thus, among the 253 prediction interals made by the Random Forests grown on the training data "train2", 215 of them actually contain the observed values in "medv", which is approximately 85.0%. This implies that the prediction intervals of "medv" based on Random Forests are not as accurate, in this particular case using the Boston Housing dataset. 

## Simulation Studies to Investigate RF and LM Prediction Intervals

### Define the function Results: outputs MSE, Avg.Width, Coverage Rate for LR & RF

```{r}
Results <- function(traindata, testdata, nodesize){

Results <- matrix(NA, nrow=2,ncol=3)
##################
#### Linear Regression Model

#Fit a linear model with all predictors
m <- lm(data=traindata,y~.)

#Predction intervals by m1 for each simulated value of y
PI <- data.frame(predict(m, newdata=testdata, interval="prediction", level=0.95))

#Count how many values of "testdata" lie in the prediction intervals by PI1
attempt <- PI$lwr <= testdata$y  & testdata$y <= PI$upr
s=0
for (k in 1:(length(attempt))) {
  if (attempt[k] == "TRUE"){s <- s+1}
}

# MSE
Results[1,1] <- sum((PI$fit - testdata$y)^2)
# Avg. width of the prediction intervals
Results[1,2] <- mean(PI$upr-PI$lwr)#sum(PI[,3]-PI[,2])/(dim(PI)[[1]])
#Coverage Rate of the prediction intervals by LR
Results[1,3] <- s/(length(attempt))

####################################
#### Random Forests 
library(randomForestSRC)

#Grow Forests on the training dataset "trainOne"
ranfor <- quantreg(y~., data = traindata,  spritrule="mse", nodesize=nodesize)
#Apply the grown model on the test set "test1"
rfTest <- quantreg(object=ranfor, newdata=testdata)

#Prediction intervals for the test set
Pinter <- get.quantile(rfTest, c(.025,.975))

#Count how many values of "test1" lie in the prediction intervals by Pinter1
check <- Pinter[,1] <= testdata$y & testdata$y <= Pinter[,2]
z=0
for (k in 1:(length(check))) {
  if (check[k] == "TRUE"){z <- z+1}
}

#### MSE
Results[2,1] <- sum((testdata$y - rfTest$predicted)^2)
#### Avg. width of the prediction intervals 
Results[2,2] <- mean(Pinter[,2]-Pinter[,1])#sum(Pinter[,2] - Pinter[,1])/(dim(Pinter)[1])
####Counts of the values of testdata that lie in the prediction intervals by RF
Results[2,3] <- z/(length(check))

#Define the output of this function
return(Results)
}
```

### Define a function Tabs: computes the tables with nodesizes of 1,5,10. 

```{r}
Tabs <- function(n, sig, equation, loops){
i <- loops
#Make a result storing array: MSE, Avg. Width, # in PI
rec <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
his <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
tra <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#set.seed(06232019)

#Make a For Loop
for (t in 1:i) {

x<- runif(n, 0, 10) #generate x variable Unif(0,10) distribution
e <- rnorm(n, 0, sig) #generate error term 
y <- equation #generate response values 

data <- data.frame(x, y) #combine explanatory and response varables into data frame
trainOne <- data[1:(n/2), ] #1st half of observations as training data
test <- data[(n/2+1):n, ] #2nd half of observations as test data

#rec1
rec[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  1)
#his1
his[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  5)
#tra1
tra[,,t] <- Results(traindata=trainOne, testdata=test, nodesize = 10)
}

#Average over i=1:10
recTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    recTab[k,j] <- mean(rec[k,j,])
  }
}

hisTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    hisTab[k,j] <- mean(his[k,j,])
  }
}

traTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    traTab[k,j] <- mean(tra[k,j,])
  }
}

return(list("results"=list("nodesizeOne"=rec, "nodesizeFive"=his, "nodesizeTen"=tra), "Avg.results"=list("nodesizeOne"=recTab, "nodesizeFive"=hisTab, "nodesizeTen"=traTab) ))

}
```


### Simulation 1: Linear Model (one variable)

```{r}
set.seed(06232019)#set seed

resultat1 <- Tabs(n=2000, sig=5, equation=2*x+3+e, loops=10)
```

### Simulation 2: Nonlinear Model (one variable)

```{r}
set.seed(06232019)#set seed

resultat2 <- Tabs(n=2000, sig=5, equation=0.1*(x-7)^2-3*cos(x) + 5*log(abs(x)) + 3 + e, loops=10)
```

### Define a function "mTabs": multi-variable version of Tabs

```{r}
mTabs <- function(n, sig, equation, loops){
i <- loops
#Make a result storing array: MSE, Avg. Width, # in PI
rec <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
his <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
tra <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#set.seed(06232019)

#Make a For Loop
for (t in 1:i) {

xvec <- runif(n*10, 0, 10) #generate observations for 10 explanatory variables
X <- matrix(xvec, ncol=10) #arrange explanatory variables into matrix
e <- rnorm(n , 0, sig) #generate error term 
y <- equation #generate response values 

data <- data.frame(x, y) #combine explanatory and response varables into data frame
trainOne <- data[1:(n/2), ] #1st half of observations as training data
test <- data[(n/2+1):n, ] #2nd half of observations as test data

#rec1
rec[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  1)
#his1
his[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  5)
#tra1
tra[,,t] <- Results(traindata=trainOne, testdata=test, nodesize = 10)
}

#Average over i=1:10
recTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    recTab[k,j] <- mean(rec[k,j,])
  }
}

hisTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    hisTab[k,j] <- mean(his[k,j,])
  }
}

traTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    traTab[k,j] <- mean(tra[k,j,])
  }
}

return(list("results"=list("nodesizeOne"=rec, "nodesizeFive"=his, "nodesizeTen"=tra), "Avg.results"=list("nodesizeOne"=recTab, "nodesizeFive"=hisTab, "nodesizeTen"=traTab) ))
}
```


### Simulation 3: Linear Model (multivariate)

```{r}
set.seed(06232019)#set seed

resultat3 <- Tabs(n=2000, sig=5, equation=2*X[,1]+3*X[,4]+4*X[,6]-3*X[,7]+ X[,9] + e, loops=10)
```

### Simulation 4: Nonlinear Model (multivariate)

```{r}
set.seed(06232019)#set seed

resultat4 <- Tabs(n=2000, sig=5, equation=(X[,1]-6)^2 + 12*cos(X[,3]) + (X[,7]-5)*(X[,8]-3) + 0.02*(X[,10]-5)^5 + e , loops=10)
```

### Summarize the Results

```{r}
Fin <- list(nodesizeONE=list(SimOne=rec1Tab,SimTwo=rec2Tab, SimThree=rec3Tab, SimFour=rec4Tab), nodesizeFive=list(SimOne=his1Tab, SimTwo=his2Tab, SimThree=his3Tab,SimFour=his4Tab), nodesizeTen=list(SimOne=tra1Tab, SimTwo=tra2Tab, SimThree=tra3Tab, SimFour=tra4Tab))
```


## Tuning the Paramters 

### Set Up 

```{r}
n <- 2000  #number of observations (training and test set combined)
sig <- 5  #error standard deviation
i <- 10
```

### Define a function "Tuned": computes the three values using quantreg with optimal nodesize(1-variable)

```{r}
Tuned <- function(equation, loops, n, sig){

library(randomForestSRC)
i <- loops

#Make a result storing array: MSE, Avg. Width, # in PI
tun <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
#Vector to store each nodesize
tN <- c(rep(NA,i))


#Make a For Loop
for (t in 1:i) {

x<- runif(n, 0, 10) #generate x variable Unif(0,10) distribution
e <- rnorm(n, 0, sig) #generate error term 
y <- equation  #generate response values 

data <- data.frame(x, y) #combine explanatory and response varables into data frame
trainOne <- data[1:(n/2), ] #1st half of observations as training data
test <- data[(n/2+1):n, ] #2nd half of observations as test data

#Tune the nodesize 
tuna <- tune(y~., data=trainOne)
tN[t] <- tuna$optimal[[1]][[1]]

#tun
tun[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  tuna$optimal[[1]][[1]])

}

#Average over [,,t]
tunTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    tunTab[k,j] <- mean(tun[k,j,])
  }
}

return(list("tN"=tN, "tun"=tun, "tunTab"=tunTab))
}
```



### Simulation 1

```{r}
set.seed(06232019)#set seed

forSim1 <- Tuned(equation=2*x+3+e, loops=10, n=2000, sig=5)
t1 <- forSim1
```

### Simulation 2

```{r}
set.seed(06232019)#set seed
forSim2 <- Tuned(equation=0.1*(x-7)^2-3*cos(x) + 5*log(abs(x)) + 3 + e, loops=10, n=2000, sig=5)
t2 <- forSim2
```

### Define a function "mTuned" multi-variable version of Tuned

```{r}
mTuned <- function(equation, loops, n, sig){

library(randomForestSRC)
i <- loops

#Make a result storing array: MSE, Avg. Width, # in PI
tun <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))
#Vector to store each nodesize
tN <- c(rep(NA,i))


#Make a For Loop
for (t in 1:i) {

xvec <- runif(n*10, 0, 10) #generate observations for 10 explanatory variables
X <- matrix(xvec, ncol=10) #arrange explanatory variables into matrix
e <- rnorm(n , 0, sig) #generate error term 
y <- equation  #generate response values

data <- data.frame(X, y) #combine explanatory and response varables into data frame
trainOne <- data[1:(n/2), ] #1st half of observations as training data
test <- data[(n/2+1):n, ] #2nd half of observations as test data

#Tune the nodesize 
tuna <- tune(y~., data=trainOne)
tN[t] <- tuna$optimal[[1]][[1]]

#tun
tun[,,t] <- Results(traindata=trainOne, testdata=test, nodesize =  tuna$optimal[[1]][[1]])

}

#Average over [,,t]
tunTab <- matrix(NA, nrow=2, ncol=3, dimnames = list(c("LR","RF"),c("Avg.MSE","Avg.Wid","Avg.CR")))

for (k in 1:2) {
  for (j in 1:3) {
    tunTab[k,j] <- mean(tun[k,j,])
  }
}

return(list("tN"=tN, "tun"=tun, "tunTab"=tunTab))
}
```


### Simulation 3

```{r}
set.seed(06232019)#set seed
forSim3 <- mTuned(equation=2*X[,1]+3*X[,4]+4*X[,6]-3*X[,7]+ X[,9] + e, loops=10, n=2000, sig=5)
t3 <- forSim3
```

### Simulation 4

```{r}
set.seed(06232019)#set seed
forSim4 <- mTuned(equation=(X[,1]-6)^2 + 12*cos(X[,3]) + (X[,7]-5)*(X[,8]-3) + 0.02*(X[,10]-5)^5+ e, loops=10, n=2000, sig=5)
t4 <- forSim4
```


## New Statistical Index? 

Seek to invent a statistical index that combines Avg.MSE & Avg. Width of PI-s & Avg.Coverage Rate to compare the predictive performances of two prediction models on a same dataset. 

Call this index "q". It should be such that: 
  -Lies in [0,1]
  -Increases for the predictive models that performs better
  -Increases for smaller MSE
  -Increases for narrower width 
  -Increases for higher coverage rate

```{r}
#A sinple, rough idea might be: 
q <- list(rec=list(), his=list(), tra=list())

for (k in 1:3) {
for (t in 1:4) {
q[[k]][[t]] <- matrix(c(c("LR","RF"),c(Fin[[k]][[t]][1,3]/(Fin[[k]][[t]][1,2]*Fin[[k]][[t]][1,1]),Fin[[k]][[t]][2,3]/(Fin[[k]][[t]][2,2]*Fin[[k]][[t]][2,1]))), nrow=2, ncol=2, byrow=TRUE)
}
}
```


