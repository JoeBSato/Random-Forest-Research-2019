---
title: "Decision Trees Lab"
author: "Joe Sato"
date: "6/17/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Setups

```{r}
set.seed(1)
#Contains the dataset Boston
library(MASS)

#Package for Random Forest
library(randomForest)

#Train Dataset (?)
train = sample (1: nrow(Boston), nrow(Boston)/2)

#Test Dataset (?)
medv=Boston [-train ,"medv"]
```

## Examine Boston Data: plot medv/each predictor (non-categorical ones)

```{r}
#Per capita crime rate by town
plot(log(Boston$crim), Boston$medv) #not sure if log transform on the predictor is ok

#Avg. # of rooms per dwelling
plot(Boston$rm, Boston$medv) #decent linear relationship

#Proportion of owner-occupied units built prior to 1940
plot(Boston$age, Boston$medv) #negative linear relationship, makes sense

#Weighted mean of distances to 5 Boston employment centres
plot(Boston$dis, Boston$medv) #why is it kinda positive linear; should be negative

#Lower status of the population (percent)
plot(Boston$lstat, Boston$medv) #"lower status"? The reputation of town?
```

## Perform Bagging
```{r}
set.seed(1)

#Perform Bagging
bag.boston1 = randomForest(medv~., data=Boston, subset=train,
mtry=13, importance =TRUE)

bag.boston1

#Make a prediction
yhat.bag1 = predict (bag.boston1, newdata=Boston[-train,])

#Measured squared error
MSEbag <- mean((yhat.bag1 - medv)^2)
```

## Bagging with # of trees specified (n=25)

```{r}
bag.boston2 = randomForest(medv~., data=Boston, subset=train,
mtry=13, ntree=25)

yhat.bag2 = predict (bag.boston2, newdata=Boston[-train,])

#Measured squared error: larger than the previously calculated MSE
MSEbag25 <- mean((yhat.bag2 - medv)^2)
```

## Grow a Random Forest

```{r}
set.seed (1)

rf.boston = randomForest(medv~., data=Boston, subset=train,
mtry=6, importance =TRUE)

yhat.rf = predict (rf.boston, newdata=Boston[-train,])

#MSE
MSErf <- mean( (yhat.rf - medv)^2 )
```

## Fit Linear Regression 

### Identify a justifiable linear model via variable elimination
Seek to eliminate the predictors of little importance via p-values; linear regression is not the objective here, so no need to do this intricately. Below is shown that crim, indus, chas,age, and tax have relatively high p-values, so eliminate these. (Though eliminating age is a little concerning.)

```{r}
#Fit linear regression 
f0 <- lm(data=Boston, medv ~ .)
summary(f0)$coefficients[,4]#each p-value
```

The list below shows that zn and rad have relatively large p-values; eliminate these two. 

```{r}
#Fit linear regression without the five predictors 
f1 <- lm(data=Boston, medv ~ . - crim - indus - chas - age - tax)
summary(f1)$coefficients[,4]#each p-value
```

The result below shows that all remaining predictors have infinitisimal p-values (except "black"), justifying the precedent steps.  
```{r}
f2 <- lm(data=Boston, medv ~ . - crim - indus - chas - age - tax - zn - rad )
summary(f2)$coefficients[,4]
```

### Make predictions on medv using f0 & f2

```{r}
#Prediction of medv by f2 using "train"
f2pred <- predict(f2, newdata=Boston[-train,])

MSEf2 <- mean ((f2pred-medv)^2)

#Prediction of medv by f0 using "train"
f0pred <- predict(f0, newdata=Boston[-train,])

MSEf0 <- mean ((f0pred-medv)^2)#smaller than MSEf2; probably related to R^2 always increasing
```

## Compare MSE-s

Below is the list of the mean squared errors for Bagging, Bagging with ntrees=25, Random Forest, Linear Regression with all 13 predictors(f0), and Linear Regression with selected predictors(f2); Random Forest resulted in the smallest MSE.
```{r}
MSEs <- matrix(c(MSEbag,MSEbag25,MSErf,MSEf0,MSEf2), nrow=1, ncol=5,byrow=TRUE)
colnames(MSEs) <- c("Bagging","Bagging: n=25", "Random Forest", "LR: f0", "LR:f2")
MSEs
```

## Compute Prediction Intervals for f0 & f2

```{r}
#Predction intervals by f0 for each observed value of medv
PIf0 <- predict(f0, newdata=Boston[-train,], interval="prediction", level=0.95)#too much gap between up & low? 

#Count how many of yhat.rf values lie in the prediction intervals by PIf0
YN <- c(rep(NA,253))
for (k in 1:253) {
  if (yhat.rf[k] <= PIf0[k,3] & yhat.rf[k] >= PIf0[k,2]) {YN[k] <- "Y"}
  else {YN[k] <- "N"}
}

t=0
#Count the number of Y in YN, then compute #Y/253
for (k in 1:253) {
  if (YN[k] == "Y"){t <- t+1}
}
t
```

Thus, among the 253 predictions made by Random Forest, 251 of them lie in the corresponding prediction intervals obtained by Linear Regression model with all 13 predictors(f0).

```{r}
#Predction intervals by f2 for each observed value of medv
PIf2 <- predict(f2, newdata=Boston[-train,], interval="prediction", level=0.95)

#Count how many of yhat.rf values lie in the prediction intervals by PIf2
YN2 <- c(rep(NA,253))
for (k in 1:253) {
  if (yhat.rf[k] <= PIf2[k,3] & yhat.rf[k] >= PIf2[k,2]) {YN2[k] <- "Y"}
  else {YN2[k] <- "N"}
}

t2=0
#Count the number of Y in YN2, then compute #Y/253
for (k in 1:253) {
  if (YN2[k] == "Y"){t2 <- t2+1}
}
t2
```

Thus, among the 253 predictions made by Random Forest, 252 of them lie in the corresponding prediction intervals obtained by Linear Regression model with selected predictors(f2). 


```{r}
#Count how many of medv values lie in the prediction intervals by PIf2
YN3 <- c(rep(NA,253))
for (k in 1:253) {
  if (medv[k] <= PIf2[k,3] & medv[k] >= PIf2[k,2]) {YN3[k] <- "Y"}
  else {YN3[k] <- "N"}
}

#Count the number of Y in YN2, then compute #Y/253
t3=0

for (k in 1:253) {
  if (YN3[k] == "Y"){t3 <- t3+1}
}

t3
```

Thus, 240/253 = 94.9% of the medv values (the test data) lie in the prediction intervals obtained via f2

```{r}
#Count how many of medv values lie in the prediction intervals by PIf0
YN4 <- c(rep(NA,253))
for (k in 1:253) {
  if (medv[k] <= PIf0[k,3] & medv[k] >= PIf0[k,2]) {YN4[k] <- "Y"}
  else {YN4[k] <- "N"}
}

#Count the number of Y in YN2, then compute #Y/253
t4=0

for (k in 1:253) {
  if (YN4[k] == "Y"){t4 <- t4+1}
}

t4
```

Thus, 242/253 = 95.7% of the medv values (the test data) lies in the prediction intervals obtained via f0. 

## Compute Prediction Intervals for Random Forest via randomForestSRC

```{r}
library(randomForestSRC)
set.seed(1)
qrf  <- quantreg(medv~., data = Boston)

#quantile regresssion with mse splitting
qrf1 <- quantreg(medv~., data = Boston, spritrule="mse", nodesize=1)

#0.05, 0.95 quantiles 
qt <- get.quantile(qrf1, c(.05, .95)) #dim(qt)=[506 3]
```

```{r}
train2 <- Boston[train,]

#Grow Forests on the training dataset "train2"
qrf2 <-    quantreg(medv~., data = train2,  spritrule="mse", nodesize=1)

#Apply the grown model on the test set Boston[-train,]
qrTest2 <- quantreg(object=qrf2, newdata=Boston[-train,])

#Get the prediction intervals for the predictions on the test set
qt2 <- get.quantile(qrTest2, c(.05,.95))

#qrTest2$predicted

#qrf22 <- quantreg(medv~., data=train2)
#qtTest <- quantreg(object=qrf22, newdata=Boston[-train2,])
#qtPItest <- get.quantile(qtTest, c(.05, .95))
```

```{r}
#Count how many of medv values lie in the prediction intervals by qtPItest
YN4 <- c(rep(NA,253))
for (k in 1:253) {
  if (qt2[k,1] <= medv[k]  & medv[k] <= qt2[k,2]) {YN4[k] <- "Y"}
  else {YN4[k] <- "N"}
}

t4=0
#Count the number of Y in YN4, then compute #Y/253
for (k in 1:253) {
  if (YN4[k] == "Y"){t4 <- t4+1}
}
t4
```

Thus, among the 253 prediction interals made by the Random Forests grown on the training data "train2", 215 of them actually contain the observed values in "medv", which is approximately 85.0%. This implies that the prediction intervals of "medv" based on Random Forests are not as accurate, in this particular case using the Boston Housing dataset. 

## Simulation Studies to Investigate RF and LM Prediction Intervals

### Simulation 1: Linear Model (one variable)

```{r}
##################
#Simulate 

set.seed(06232019)#set seed
n <- 2000  #number of observations (training and test set combined)
sig1 <- 5  #error standard deviation
i <- 10

#Make a result storing array: MSE, Avg. Width, # in PI
rec1 <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#Make a For Loop
for (t in 1:i) {
  

x1 <- runif(n, 0, 10) #generate x variable Unif(0,10) distribution
e1 <- rnorm(n, 0, sig1) #generate error term 
y1 <- 2*x1+3 + e1  #generate response values 

data1 <- data.frame(x1, y1) #combine explanatory and response varables into data frame
trainOne <- data1[1:(n/2), ] #1st half of observations as training data
test1 <- data1[(n/2+1):n, ] #2nd half of observations as test data

##################
#### Linear Regression Model

#Fit a linear model with all predictors
m1 <- lm(data=trainOne, y1~.)

#Predction intervals by m1 for each simulated value of y
PI1 <- predict(m1, newdata=test1, interval="prediction", level=0.95)

# MSE
rec1[1,1,t] <- sum((PI1[,1] - test1[,2])^2)
#Avg. width of the prediction intervals
rec1[1,2,t] <- sum(PI1[,3]-PI1[,2])/(n/2)

#Count how many values of "test" lie in the prediction intervals by PI1
attempt1 <- PI1[,2] <= test1[,2]  & test1[,2] <= PI1[,3]

s1=0
for (k in 1:(n/2)) {
  if (attempt1[k] == "TRUE"){s1 <- s1+1}
}
rec1[1,3,t] <- s1

####################################
# Random Forests 
library(randomForestSRC)

#Grow Forests on the training dataset "trainOne"
rf1 <-    quantreg(y1~., data = trainOne,  spritrule="mse", nodesize=1)
#Apply the grown model on the test set "test1"
rfTest1 <- quantreg(object=rf1, newdata=test1)

#### MSE
rec1[2,1,t] <- sum((test1 - rfTest1$predicted)^2)

#Prediction intervals for the test set
Pinter1 <- get.quantile(rfTest1, c(.05,.95))

#### Avg. width of the prediction intervals 
rec1[2,2,t] <- sum(Pinter1[,2] - Pinter1[,1])/length(Pinter1)

####Count how many values of "test1" lie in the prediction intervals by Pinter1
check1 <- Pinter1[,1] <= test1[,2] & test1[,2] <= Pinter1[,2]

z1=0
for (k in 1:(n/2)) {
  if (check1[k] == "TRUE"){z1 <- z1+1}
}
rec1[2,3,t] <- z1

}
```

### Simulation 2: Nonlinear Model (one variable)

#### Simulate

```{r}
set.seed(06232019)#set seed
n2 <- 2000  #number of observations (training and test set combined)
sig2 <- 5  #error standard deviation

x2 <- runif(n2, 0, 10) #generate x variable Unif(0,10) distribution
e2 <- rnorm(n2, 0, sig2) #generate error term 
y2 <- 0.1*(x2-7)^2-3*cos(x2) + 5*log(abs(x2)) + 3 + e2  #generate response values 

data2 <- data.frame(x2, y2) #combine explanatory and response varables into data frame
trainTwo <- data2[1:(n2/2), ] #use first half of observations as training data
test2 <- data2[(n2/2+1):n2, ] #use second half of observations as test data
```

```{r}
##################
#Simulate 

set.seed(06232019)#set seed
n <- 2000  #number of observations (training and test set combined)
sig1 <- 5  #error standard deviation
i <- 10

#Make a result storing array: MSE, Avg. Width, # in PI
rec2 <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#Make a For Loop
for (t in 1:i) {
  

x1 <- runif(n, 0, 10) #generate x variable Unif(0,10) distribution
e1 <- rnorm(n, 0, sig1) #generate error term 
y1 <- 0.1*(x1-7)^2-3*cos(x1) + 5*log(abs(x1)) + 3 + e1  #generate response values

data1 <- data.frame(x1, y1) #combine explanatory and response varables into data frame
trainOne <- data1[1:(n/2), ] #1st half of observations as training data
test1 <- data1[(n/2+1):n, ] #2nd half of observations as test data

##################
#### Linear Regression Model

#Fit a linear model with all predictors
m1 <- lm(data=trainOne, y1~.)

#Predction intervals by m1 for each simulated value of y
PI1 <- predict(m1, newdata=test1, interval="prediction", level=0.95)

# MSE
rec2[1,1,t] <- sum((PI1[,1] - test1[,2])^2)
#Avg. width of the prediction intervals
rec2[1,2,t] <- sum(PI1[,3]-PI1[,2])/(n/2)

#Count how many values of "test" lie in the prediction intervals by PI1
attempt1 <- PI1[,2] <= test1[,2]  & test1[,2] <= PI1[,3]

s1=0
for (k in 1:(n/2)) {
  if (attempt1[k] == "TRUE"){s1 <- s1+1}
}
rec2[1,3,t] <- s1

####################################
# Random Forests 
library(randomForestSRC)

#Grow Forests on the training dataset "trainOne"
rf1 <-    quantreg(y1~., data = trainOne,  spritrule="mse", nodesize=1)
#Apply the grown model on the test set "test1"
rfTest1 <- quantreg(object=rf1, newdata=test1)

#### MSE
rec2[2,1,t] <- sum((test1 - rfTest1$predicted)^2)

#Prediction intervals for the test set
Pinter1 <- get.quantile(rfTest1, c(.05,.95))

#### Avg. width of the prediction intervals 
rec2[2,2,t] <- sum(Pinter1[,2] - Pinter1[,1])/length(Pinter1)

####Count how many values of "test1" lie in the prediction intervals by Pinter1
check1 <- Pinter1[,1] <= test1[,2] & test1[,2] <= Pinter1[,2]

z1=0
for (k in 1:(n/2)) {
  if (check1[k] == "TRUE"){z1 <- z1+1}
}
rec2[2,3,t] <- z1

}
```

#### Prediction Intervals from Linear Regression Model

```{r}
#Fit a linear model with all predictors
m2 <- lm(data=trainTwo, y2~.)

#Predction intervals by m1 for each simulated value of y
PI2 <- predict(m2, newdata=test2, interval="prediction", level=0.95)

#Count how many values of "test" lie in the prediction intervals by PI1
ON2 <- c(rep(NA,n2/2))

for (k in 1:(n2/2)) {
  if (PI2[k,2] <= test2[k,2]  & test2[k,2] <= PI2[k,3]) {ON2[k] <- "Y"}
  else {ON2[k] <- "N"}
}


#Count the number of Y in ON1, then compute #Y/(n/2)
s2=0

for (k in 1:(n2/2)) {
  if (ON2[k] == "Y"){s2 <- s2+1}
}
s2
```

#### Prediction INtervals from Random Forests

```{r}
#Grow Forests on the training dataset "trainTwo"
rf2 <-    quantreg(y2~., data = trainTwo,  spritrule="mse", nodesize=1)

#Apply the grown model on the test set "test2"
rfTest2 <- quantreg(object=rf2, newdata=trainTwo)

#Get the prediction intervals for the predictions on the test set
Pinter2 <- get.quantile(rfTest2, c(.05,.95))
```

```{r}
#Count how many values of "test2" lie in the prediction intervals by Pinter2
check2 <- c(rep(NA,n/2))

for (k in 1:n/2) {
  if (Pinter2[k,1] <= test2[k,2]  & test2[k,2] <= Pinter2[k,2]) {check2[k] <- "Y"}
  else {check2[k] <- "N"}
}


#Count the number of Y in check2, then compute #Y/(n/2)
z2=0

for (k in 1:n/2) {
  if (check2[k] == "Y"){z2 <- z2+1}
}
z2
```

### Simulation 3: Linear Model (multivariate)

#### Simulate

```{r}
##################
#Simulate 

set.seed(06232019)#set seed
n <- 2000  #number of observations (training and test set combined)
sig1 <- 5  #error standard deviation
i <- 10

#Make a result storing array: MSE, Avg. Width, # in PI
rec3 <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#Make a For Loop
for (t in 1:i) {
  
xvec <- runif(n*10, 0, 10) #generate observations for 10 explanatory variables
X <- matrix(xvec, ncol=10) #arrange explanatory variables into matrix
e <- rnorm(n , 0, sig1) #generate error term 
y <- 2*X[,1]+3*X[,4]+4*X[,6]-3*X[,7]+ X[,9] + e  #generate response values

data1 <- data.frame(X, y) #combine explanatory and response varables into data frame
trainOne <- data1[1:(n/2), ] #1st half of observations as training data
test1 <- data1[(n/2+1):n, ] #2nd half of observations as test data

##################
#### Linear Regression Model

#Fit a linear model with all predictors
m1 <- lm(data=trainOne, y~.)

#Predction intervals by m1 for each simulated value of y
PI1 <- predict(m1, newdata=test1, interval="prediction", level=0.95)

# MSE
rec3[1,1,t] <- sum((PI1[,1] - test1[,2])^2)
#Avg. width of the prediction intervals
rec3[1,2,t] <- sum(PI1[,3]-PI1[,2])/(n/2)

#Count how many values of "test" lie in the prediction intervals by PI1
attempt1 <- PI1[,2] <= test1[,2]  & test1[,2] <= PI1[,3]

s1=0
for (k in 1:(n/2)) {
  if (attempt1[k] == "TRUE"){s1 <- s1+1}
}
rec3[1,3,t] <- s1

####################################
# Random Forests 
library(randomForestSRC)

#Grow Forests on the training dataset "trainOne"
rf1 <-    quantreg(y~., data = trainOne,  spritrule="mse", nodesize=1)
#Apply the grown model on the test set "test1"
rfTest1 <- quantreg(object=rf1, newdata=test1)

#### MSE
rec3[2,1,t] <- sum((test1 - rfTest1$predicted)^2)

#Prediction intervals for the test set
Pinter1 <- get.quantile(rfTest1, c(.05,.95))

#### Avg. width of the prediction intervals 
rec3[2,2,t] <- sum(Pinter1[,2] - Pinter1[,1])/length(Pinter1)

####Count how many values of "test1" lie in the prediction intervals by Pinter1
check1 <- Pinter1[,1] <= test1[,2] & test1[,2] <= Pinter1[,2]

z1=0
for (k in 1:(n/2)) {
  if (check1[k] == "TRUE"){z1 <- z1+1}
}
rec3[2,3,t] <- z1

}
```

#### Prediction Intervals from Linear Regression Model

```{r}
#Fit a linear model with all predictors
m3 <- lm(data=trainThree, y~.)

#Predction intervals by m1 for each simulated value of y
PI3 <- predict(m3, newdata=test3, interval="prediction", level=0.95)

#Count how many values of "test" lie in the prediction intervals by PI3
ON3 <- c(rep(NA,n3/2))

for (k in 1:n3/2) {
  if (PI3[k,2] <= test3[k,2]  & test3[k,2] <= PI3[k,3]) {ON3[k] <- "Y"}
  else {ON3[k] <- "N"}
}


#Count the number of Y in ON3, then compute #Y/(n/2)
s3=0

for (k in 1:n3/2) {
  if (ON3[k] == "Y"){s3 <- s3+1}
}
s3
```

#### Predcition Intervals from Random Forests

```{r}
#Grow Forests on the training dataset "trainThree"
rf3 <-    quantreg(y3~., data = trainThree,  spritrule="mse", nodesize=1)

#Apply the grown model on the test set "test3"
rfTest3 <- quantreg(object=rf3, newdata=trainThree)

#Get the prediction intervals for the predictions on the test set
Pinter3 <- get.quantile(rfTest3, c(.05,.95))
```

```{r}
#Count how many values of "test3" lie in the prediction intervals by Pinter3
check3 <- c(rep(NA,n/2))

for (k in 1:n/2) {
  if (Pinter3[k,1] <= test3[k,2]  & test3[k,2] <= Pinter3[k,2]) {check3[k] <- "Y"}
  else {check3[k] <- "N"}
}


#Count the number of Y in check3, then compute #Y/(n/2)
z3=0

for (k in 1:n/2) {
  if (check3[k] == "Y"){z3 <- z3+1}
}
z3
```

### Simulation 4: Nonlinear Model (multivariate)

#### Simulate

```{r}

xvec4 <- runif(n*10, 0, 10) #generate observations for 10 explanatory variables
X4 <- matrix(xvec4, ncol=10) #arrange explanatory variables into matrix

e4 <- rnorm(n, 0, sig) #generate error term 
y4 <- (X4[,1]-6)^2 + 12*cos(X4[,3]) + (X4[,7]-5)*(X4[,8]-3) + 0.02*(X4[,10]-5)^5+ e4  #generate response values 

data4 <- data.frame(X4, y4) #combine explanatory and response varables into data frame
trainFour <- data4[1:(n/2), ] #use first half of observations as training data
test4 <- data4[(n/2+1):n, ] #use second half of observations as test data
```

```{r}
##################
#Simulate 

set.seed(06232019)#set seed
n <- 2000  #number of observations (training and test set combined)
sig1 <- 5  #error standard deviation
i <- 10

#Make a result storing array: MSE, Avg. Width, # in PI
rec4 <- array(NA, dim=c(2,3, i), dimnames=list(c("LR","RF"),c("MSE","avg.width","# in PI"),c(1:i)))

#Make a For Loop
for (t in 1:i) {

xvec <- runif(n*10, 0, 10) #generate observations for 10 explanatory variables
X <- matrix(xvec, ncol=10) #arrange explanatory variables into matrix
e <- rnorm(n, 0, sig1) #generate error term 
y <- (X[,1]-6)^2 + 12*cos(X[,3]) + (X[,7]-5)*(X[,8]-3) + 0.02*(X[,10]-5)^5+ e  #generate response values

data1 <- data.frame(X, y) #combine explanatory and response varables into data frame
trainOne <- data1[1:(n/2), ] #1st half of observations as training data
test1 <- data1[(n/2+1):n, ] #2nd half of observations as test data

##################
#### Linear Regression Model

#Fit a linear model with all predictors
m1 <- lm(data=trainOne, y~.)

#Predction intervals by m1 for each simulated value of y
PI1 <- predict(m1, newdata=test1, interval="prediction", level=0.95)

# MSE
rec4[1,1,t] <- sum((PI1[,1] - test1[,2])^2)
#Avg. width of the prediction intervals
rec4[1,2,t] <- sum(PI1[,3]-PI1[,2])/(n/2)

#Count how many values of "test" lie in the prediction intervals by PI1
attempt1 <- PI1[,2] <= test1[,2]  & test1[,2] <= PI1[,3]

s1=0
for (k in 1:(n/2)) {
  if (attempt1[k] == "TRUE"){s1 <- s1+1}
}
rec4[1,3,t] <- s1

####################################
# Random Forests 
library(randomForestSRC)

#Grow Forests on the training dataset "trainOne"
rf1 <-    quantreg(y~., data = trainOne,  spritrule="mse", nodesize=1)
#Apply the grown model on the test set "test1"
rfTest1 <- quantreg(object=rf1, newdata=test1)

#### MSE
rec4[2,1,t] <- sum((test1 - rfTest1$predicted)^2)

#Prediction intervals for the test set
Pinter1 <- get.quantile(rfTest1, c(.05,.95))

#### Avg. width of the prediction intervals 
rec4[2,2,t] <- sum(Pinter1[,2] - Pinter1[,1])/length(Pinter1)

####Count how many values of "test1" lie in the prediction intervals by Pinter1
check1 <- Pinter1[,1] <= test1[,2] & test1[,2] <= Pinter1[,2]

z1=0
for (k in 1:(n/2)) {
  if (check1[k] == "TRUE"){z1 <- z1+1}
}
rec4[2,3,t] <- z1

}
```

#### Prediction Intervals from Linear Regression Model

```{r}
#Fit a linear model with all predictors
m4 <- lm(data=trainThree, y4~.)

#Predction intervals by m1 for each simulated value of y
PI4 <- predict(m4, newdata=test4, interval="prediction", level=0.95)

#Count how many values of "test" lie in the prediction intervals by PI4
ON4 <- c(rep(NA,n/2))

for (k in 1:n/2) {
  if (PI4[k,2] <= test4[k,2]  & test4[k,2] <= PI4[k,3]) {ON4[k] <- "Y"}
  else {ON4[k] <- "N"}
}


#Count the number of Y in ON4, then compute #Y/(n/2)
s4=0

for (k in 1:n/2) {
  if (ON4[k] == "Y"){s4 <- s4+1}
}
s4
```

#### Prediction Intervals from Random Forests

```{r}
#Grow Forests on the training dataset "trainFour"
rf4 <-    quantreg(y4~., data = trainFour,  spritrule="mse", nodesize=1)

#Apply the grown model on the test set "test4"
rfTest4 <- quantreg(object=rf4, newdata=trainFour)

#Get the prediction intervals for the predictions on the test set
Pinter4 <- get.quantile(rfTest4, c(.05,.95))
```

```{r}
#Count how many values of "test4" lie in the prediction intervals by Pinter4
check4 <- c(rep(NA,n/2))

for (k in 1:n/2) {
  if (Pinter4[k,1] <= test4[k,2]  & test4[k,2] <= Pinter4[k,2]) {check4[k] <- "Y"}
  else {check4[k] <- "N"}
}


#Count the number of Y in check4, then compute #Y/(n/2)
z4=0

for (k in 1:n/2) {
  if (check4[k] == "Y"){z4 <- z4+1}
}
z4
```

```{r}
save.image(file = "LR & RF comparison.Rdata")
```




